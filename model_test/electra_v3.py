from transformers import AutoTokenizer, TextGeneration
import torch, time

model_name = "monologg/koelectra-small-v3-discriminator"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = TextGeneration.from_pretrained(model_name)

text = "ì˜¤ëŠ˜ ë‚ ì”¨ ì–´ë•Œ?"
inputs = tokenizer(text, return_tensors="pt")

start = time.time()
with torch.no_grad():
    outputs = model(**inputs)
end = time.time()

print("ğŸ”¹ logits:", outputs.logits)
print("â±ï¸ ì¶”ë¡  ì‹œê°„:", end - start, "ì´ˆ")
